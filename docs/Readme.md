# SparkSQL with Python

<p>

This repository has some examples of using Spark and SparkSQL with Python through PySpark

## Profeco

We will work with the Profeco dataset, which you can download here: [Profeco](https://drive.google.com/uc?export=download&id=0B-4W2dww7ELNazFfOFVhNG5vckE) , is a daily historical record of more than 2,000 products, as of 2015, in various establishments in Mexico

<details closed>
<summary> <a href="https://wittline.github.io/SparkSQL-with-Python/Profeco.html">Check the code here</a> </summary>
</details>

**How many records are there?** 

**How many categories are there?**

**How many trade chains are being monitored (and therefore reported in that database)?**

**What are the most monitored products in each state of the country?**

**What is the trade chain with the greatest variety of monitored products?**



## Countries airports


<details closed>
<summary> <a href="https://wittline.github.io/SparkSQL-with-Python/Airports.html">Check the code here</a> </summary>
</details>


## API to count the number of tweets in a radius of 1km

I will separate in another file "tweets_geo.csv" all the different tweets with their geographic data information, this will help in the manipulation of this data in a query with sparkSQL

<details closed>
<summary> <a href="https://wittline.github.io/SparkSQL-with-Python/Tweet_Count.html">Check the data preparation code here</a> </summary>
</details>

The details of the code for the API REST is in the folder API in this repository

![alt text](https://wittline.github.io/SparkSQL-with-Python/Images/Api1.PNG)

![alt text](https://wittline.github.io/SparkSQL-with-Python/Images/Api2.PNG)

![alt text](https://wittline.github.io/SparkSQL-with-Python/Images/Api3.PNG)


</p>

